{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZdWTNGujKS1","executionInfo":{"status":"ok","timestamp":1725895044463,"user_tz":-60,"elapsed":18192,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}},"outputId":"dd201282-914f-4bbc-fa08-7253ebccaa3b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jQsi186WicIy","executionInfo":{"status":"ok","timestamp":1725895053435,"user_tz":-60,"elapsed":7852,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"outputs":[],"source":["from keras import Model, Input, layers, optimizers, losses, metrics\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","data = pd.read_csv('./drive/MyDrive/VagusNerveResearchProject/vns_dataset_threshold_type.csv')\n","\n","data.loc[data['fibre_type'] == 'AB', 'fibre_type'] = 0.0\n","data.loc[data['fibre_type'] == 'C', 'fibre_type'] = 1.0\n","\n","# Encode the categorical feature\n","def one_hot_encode(labels, num_classes):\n","    return np.eye(num_classes)[labels]\n","\n","X_fibre_type = one_hot_encode(data[['fibre_type']].astype('int'), num_classes=2)\n","X_fibre_type = X_fibre_type.reshape(-1, 2)\n","\n","# Split the data\n","X = data.loc[:, ['nerve_a', 'nerve_b', 'activation_level', 'frequency', 'pulse_width']]\n","X.loc[:, 'fibre_type_AB'] = X_fibre_type[:, 0]\n","X.loc[:, 'fibre_type_C'] = X_fibre_type[:, 1]\n","y = data.loc[:, ['amplitude']]\n","\n","# X.loc[X['fibre_type'] == 'AB', 'fibre_type'] = 0\n","# X.loc[X['fibre_type'] == 'C', 'fibre_type'] = 1\n","# X.loc[:, 'fibre_type'] = pd.to_numeric(X['fibre_type'])"]},{"cell_type":"code","source":["X_ab = X[X['fibre_type_AB'] == 1.0]\n","X_c = X[X['fibre_type_C'] == 1.0]\n","y_ab = y[X['fibre_type_AB'] == 1.0]\n","y_c = y[X['fibre_type_C'] == 1.0]\n","\n","# Normalize the continuous features\n","X_scaler_ab = StandardScaler()\n","X_ab_norm = X_scaler_ab.fit_transform(X_ab[['nerve_a', 'nerve_b', 'activation_level', 'frequency', 'pulse_width']])\n","X_scaler_c = StandardScaler()\n","X_c_norm = X_scaler_c.fit_transform(X_c[['nerve_a', 'nerve_b', 'activation_level', 'frequency', 'pulse_width']])\n","\n","y_scaler_ab = StandardScaler()\n","y_ab_norm = y_scaler_ab.fit_transform(y_ab)\n","y_scaler_c = StandardScaler()\n","y_c_norm = y_scaler_c.fit_transform(y_c)\n","\n","X_ab_norm = np.hstack([X_ab_norm, X_ab[['fibre_type_AB', 'fibre_type_C']].values])\n","X_c_norm = np.hstack([X_c_norm, X_c[['fibre_type_AB', 'fibre_type_C']].values])\n","\n","X_norm = np.vstack([X_ab_norm, X_c_norm])\n","y_norm = np.vstack([y_ab_norm, y_c_norm])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.2, random_state=42)"],"metadata":{"id":"knGVEV3yLNgX","executionInfo":{"status":"ok","timestamp":1725895053435,"user_tz":-60,"elapsed":3,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","\n","# Define parameter grids for each model\n","param_grids = {\n","    'Linear Regression': {},\n","    'Ridge Regression': {'alpha': [0.1, 1.0, 10.0]},\n","    'Lasso Regression': {'estimator__alpha': [0.01, 0.1, 1.0]},\n","    'Elastic Net': {'estimator__alpha': [0.01, 0.1, 1.0], 'estimator__l1_ratio': [0.2, 0.5, 0.8]},\n","    'Support Vector Regression (SVR)': {'estimator__C': [0.1, 1.0, 10.0], 'estimator__epsilon': [0.01, 0.1, 0.2]},\n","    'Decision Tree Regressor': {'max_depth': [None, 5, 10, 15], 'min_samples_split': [2, 10, 20]},\n","    'Random Forest Regressor': {'n_estimators': [5, 10, 15], 'max_depth': [None, 5, 10]},\n","    'Gradient Boosting Regressor': {'estimator__n_estimators': [50, 75, 100], 'estimator__learning_rate': [0.01, 0.1, 0.2]},\n","    'K-Nearest Neighbors Regressor': {'n_neighbors': [3, 5, 7]}\n","}\n","\n","# List of models to evaluate\n","models = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(),\n","    'Lasso Regression': MultiOutputRegressor(Lasso()),\n","    'Elastic Net': MultiOutputRegressor(ElasticNet()),\n","    'Support Vector Regression (SVR)': MultiOutputRegressor(SVR(kernel='rbf')),\n","    'Decision Tree Regressor': DecisionTreeRegressor(),\n","    'Random Forest Regressor': RandomForestRegressor(),\n","    'Gradient Boosting Regressor': MultiOutputRegressor(GradientBoostingRegressor()),\n","    'K-Nearest Neighbors Regressor': KNeighborsRegressor()\n","}\n","\n","# Evaluate each model with GridSearchCV\n","for name, model in models.items():\n","    print(f'Evaluating {name}...')\n","    param_grid = param_grids[name]\n","    if param_grid:\n","        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n","        grid_search.fit(X_train, y_train)\n","        best_model = grid_search.best_estimator_\n","        print(f'Best parameters for {name}: {grid_search.best_params_}')\n","    else:\n","        best_model = model\n","        best_model.fit(X_train, y_train)\n","\n","    y_pred = best_model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred, multioutput='uniform_average')\n","    r2 = r2_score(y_test, y_pred, multioutput='uniform_average')\n","    print(f'{name} MSE: {mse:.4f}')\n","    print(f'{name} R^2: {r2:.4f}')\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3bdA5Dr7dgJX","executionInfo":{"status":"ok","timestamp":1725886195262,"user_tz":-60,"elapsed":1509314,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}},"outputId":"e9a5e7a2-7148-44d2-dc99-d7bce1f57e1f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating Linear Regression...\n","Linear Regression MSE: 0.6501\n","Linear Regression R^2: 0.3371\n","\n","Evaluating Ridge Regression...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters for Ridge Regression: {'alpha': 10.0}\n","Ridge Regression MSE: 0.6501\n","Ridge Regression R^2: 0.3371\n","\n","Evaluating Lasso Regression...\n","Best parameters for Lasso Regression: {'estimator__alpha': 0.01}\n","Lasso Regression MSE: 0.6505\n","Lasso Regression R^2: 0.3367\n","\n","Evaluating Elastic Net...\n","Best parameters for Elastic Net: {'estimator__alpha': 0.01, 'estimator__l1_ratio': 0.2}\n","Elastic Net MSE: 0.6500\n","Elastic Net R^2: 0.3373\n","\n","Evaluating Support Vector Regression (SVR)...\n","Best parameters for Support Vector Regression (SVR): {'estimator__C': 10.0, 'estimator__epsilon': 0.2}\n","Support Vector Regression (SVR) MSE: 0.1766\n","Support Vector Regression (SVR) R^2: 0.8199\n","\n","Evaluating Decision Tree Regressor...\n","Best parameters for Decision Tree Regressor: {'max_depth': 15, 'min_samples_split': 2}\n","Decision Tree Regressor MSE: 0.0000\n","Decision Tree Regressor R^2: 1.0000\n","\n","Evaluating Random Forest Regressor...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return fit_method(estimator, *args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters for Random Forest Regressor: {'max_depth': None, 'n_estimators': 15}\n","Random Forest Regressor MSE: 0.0000\n","Random Forest Regressor R^2: 1.0000\n","\n","Evaluating Gradient Boosting Regressor...\n","Best parameters for Gradient Boosting Regressor: {'estimator__learning_rate': 0.2, 'estimator__n_estimators': 100}\n","Gradient Boosting Regressor MSE: 0.0007\n","Gradient Boosting Regressor R^2: 0.9993\n","\n","Evaluating K-Nearest Neighbors Regressor...\n","Best parameters for K-Nearest Neighbors Regressor: {'n_neighbors': 3}\n","K-Nearest Neighbors Regressor MSE: 0.1009\n","K-Nearest Neighbors Regressor R^2: 0.8971\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","import pickle\n","\n","# Define parameter grids for each model\n","param_grids = {\n","    'Linear Regression': {},\n","    'Ridge Regression': {'alpha': [0.1, 1.0, 10.0]},\n","    'Lasso Regression': {'estimator__alpha': [0.01, 0.1, 1.0]},\n","    'Elastic Net': {'estimator__alpha': [0.01, 0.1, 1.0], 'estimator__l1_ratio': [0.2, 0.5, 0.8]},\n","    'Support Vector Regression (SVR)': {'estimator__C': [0.1, 1.0, 10.0], 'estimator__epsilon': [0.01, 0.1, 0.2]},\n","    # 'Decision Tree Regressor': {'max_depth': [None, 5, 10, 15], 'min_samples_split': [2, 10, 20]},\n","    # 'Random Forest Regressor': {'n_estimators': [5, 10, 15], 'max_depth': [None, 5, 10]},\n","    'Gradient Boosting Regressor': {'estimator__n_estimators': [50, 75, 100], 'estimator__learning_rate': [0.01, 0.1, 0.2]},\n","    'K-Nearest Neighbors Regressor': {'n_neighbors': [3, 5, 7]}\n","}\n","\n","# List of models to evaluate\n","models = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(),\n","    'Lasso Regression': MultiOutputRegressor(Lasso()),\n","    'Elastic Net': MultiOutputRegressor(ElasticNet()),\n","    'Support Vector Regression (SVR)': MultiOutputRegressor(SVR(kernel='rbf')),\n","    # 'Decision Tree Regressor': DecisionTreeRegressor(),\n","    # 'Random Forest Regressor': RandomForestRegressor(),\n","    'Gradient Boosting Regressor': MultiOutputRegressor(GradientBoostingRegressor()),\n","    'K-Nearest Neighbors Regressor': KNeighborsRegressor()\n","}\n","\n","def get_model_size(model):\n","    # Serialize the model using pickle\n","    serialized_model = pickle.dumps(model)\n","\n","    # Get the size of the serialized model in bytes\n","    model_size_in_bytes = len(serialized_model)\n","\n","    # Convert the size to kilobytes (optional)\n","    model_size_in_kb = model_size_in_bytes / 1024\n","    return model_size_in_kb\n","\n","# Evaluate each model with GridSearchCV\n","for name, model in models.items():\n","    print(f'Evaluating {name}...')\n","    param_grid = param_grids[name]\n","    if param_grid:\n","        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n","        grid_search.fit(X_train, y_train)\n","        best_model = grid_search.best_estimator_\n","        print(f'Best parameters for {name}: {grid_search.best_params_}')\n","    else:\n","        best_model = model\n","        best_model.fit(X_train, y_train)\n","\n","    y_pred = best_model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred, multioutput='uniform_average')\n","    r2 = r2_score(y_test, y_pred, multioutput='uniform_average')\n","    print(f'{name} MSE: {mse:.4f}')\n","    print(f'{name} R^2: {r2:.4f}')\n","    print(f'{name} model size: {get_model_size(best_model)}')\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725896571693,"user_tz":-60,"elapsed":1482827,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}},"outputId":"c516ae1a-ded6-4665-c204-a0afd096d87d","id":"gnR2hs_h4WBJ"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating Linear Regression...\n","Linear Regression MSE: 0.6501\n","Linear Regression R^2: 0.3371\n","Linear Regression model size: 0.5126953125\n","\n","Evaluating Ridge Regression...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters for Ridge Regression: {'alpha': 10.0}\n","Ridge Regression MSE: 0.6501\n","Ridge Regression R^2: 0.3371\n","Ridge Regression model size: 0.47265625\n","\n","Evaluating Lasso Regression...\n","Best parameters for Lasso Regression: {'estimator__alpha': 0.01}\n","Lasso Regression MSE: 0.6505\n","Lasso Regression R^2: 0.3367\n","Lasso Regression model size: 0.732421875\n","\n","Evaluating Elastic Net...\n","Best parameters for Elastic Net: {'estimator__alpha': 0.01, 'estimator__l1_ratio': 0.2}\n","Elastic Net MSE: 0.6500\n","Elastic Net R^2: 0.3373\n","Elastic Net model size: 0.7373046875\n","\n","Evaluating Support Vector Regression (SVR)...\n","Best parameters for Support Vector Regression (SVR): {'estimator__C': 10.0, 'estimator__epsilon': 0.2}\n","Support Vector Regression (SVR) MSE: 0.1766\n","Support Vector Regression (SVR) R^2: 0.8199\n","Support Vector Regression (SVR) model size: 631.52734375\n","\n","Evaluating Gradient Boosting Regressor...\n","Best parameters for Gradient Boosting Regressor: {'estimator__learning_rate': 0.2, 'estimator__n_estimators': 100}\n","Gradient Boosting Regressor MSE: 0.0007\n","Gradient Boosting Regressor R^2: 0.9993\n","Gradient Boosting Regressor model size: 132.728515625\n","\n","Evaluating K-Nearest Neighbors Regressor...\n","Best parameters for K-Nearest Neighbors Regressor: {'n_neighbors': 3}\n","K-Nearest Neighbors Regressor MSE: 0.1009\n","K-Nearest Neighbors Regressor R^2: 0.8971\n","K-Nearest Neighbors Regressor model size: 1967.884765625\n","\n"]}]}],"metadata":{"kernelspec":{"display_name":"ml","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"},"colab":{"provenance":[{"file_id":"1lTzC3b8lk5s5EUdPsUxN3Dch8t9Ow5bl","timestamp":1722893452338},{"file_id":"1hnNGXVfgFzUsMsUAZ_Ru9fvH1LGWk6Yu","timestamp":1722783877786},{"file_id":"1r-QqbxPA-skwXbPsllepflIWywIP1WDI","timestamp":1722766207912}]}},"nbformat":4,"nbformat_minor":0}