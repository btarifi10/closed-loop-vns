{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SZbytuwa9ERiUT3jiLr1QKFy0BXzyRTP","timestamp":1723135127416}],"machine_shape":"hm","mount_file_id":"1ro7hmDutm9Bmep1DJSx7l3fR3G31eAn1","authorship_tag":"ABX9TyNsM6XhUpw4ZXPPnir/CKD1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Load and transform the data\n","data = pd.read_csv('./drive/MyDrive/VagusNerveResearchProject/vns_dataset_threshold_type.csv')\n","\n","# data = pd.get_dummies(data, columns=['fibre_type'])\n","\n","data.loc[data['fibre_type'] == 'AB', 'fibre_type'] = 0.0\n","data.loc[data['fibre_type'] == 'C', 'fibre_type'] = 1.0\n","\n","data = data.astype('float32')\n","data.head()\n","\n","data_ab = data.loc[data['fibre_type'] == 0.0, :]\n","data_c = data.loc[data['fibre_type'] == 1.0, :]"],"metadata":{"id":"baJZOjrH3sy8","executionInfo":{"status":"ok","timestamp":1723214879486,"user_tz":-60,"elapsed":1051,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# One-Hot Encoding for Categorical Variable\n","def one_hot_encode(labels, num_classes):\n","    return np.eye(num_classes)[labels]\n","\n","X_cat = one_hot_encode(data[['fibre_type']].astype('int'), num_classes=2)\n","X_cat = X_cat.reshape(-1, 2)\n","\n","X = data.loc[:, ['nerve_a', 'nerve_b', 'activation_level', 'frequency']]\n","X.loc[:, 'fibre_type_AB'] = X_cat[:, 0]\n","X.loc[:, 'fibre_type_C'] = X_cat[:, 1]\n","\n","y = data.loc[:, ['pulse_width', 'amplitude']].values"],"metadata":{"id":"zEvX3L_y30j2","executionInfo":{"status":"ok","timestamp":1723214882481,"user_tz":-60,"elapsed":1098,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["X_ab = X[X['fibre_type_AB'] == 1.0]\n","X_c = X[X['fibre_type_C'] == 1.0]\n","y_ab = y[X['fibre_type_AB'] == 1.0]\n","y_c = y[X['fibre_type_C'] == 1.0]\n","\n","# Normalize the continuous features\n","X_scaler_ab = StandardScaler()\n","X_ab_norm = X_scaler_ab.fit_transform(X_ab[['nerve_a', 'nerve_b', 'activation_level', 'frequency']])\n","X_scaler_c = StandardScaler()\n","X_c_norm = X_scaler_c.fit_transform(X_c[['nerve_a', 'nerve_b', 'activation_level', 'frequency']])\n","\n","y_scaler_ab = StandardScaler()\n","y_ab_norm = y_scaler_ab.fit_transform(y_ab)\n","y_scaler_c = StandardScaler()\n","y_c_norm = y_scaler_c.fit_transform(y_c)\n","\n","X_ab_norm = np.hstack([X_ab_norm, X_ab[['fibre_type_AB', 'fibre_type_C']].values])\n","X_c_norm = np.hstack([X_c_norm, X_c[['fibre_type_AB', 'fibre_type_C']].values])\n","\n","X_norm = np.vstack([X_ab_norm, X_c_norm])\n","y_norm = np.vstack([y_ab_norm, y_c_norm])"],"metadata":{"id":"fzellmFG4hDG","executionInfo":{"status":"ok","timestamp":1723214884882,"user_tz":-60,"elapsed":445,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, TensorDataset, random_split\n","import torch\n","\n","X_norm = torch.tensor(X_norm, dtype=torch.float32)\n","y_norm = torch.tensor(y_norm, dtype=torch.float32)\n","\n","dataset = TensorDataset(X_norm, y_norm)\n","\n","# Random split\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"_2DFRufM4Zf7","executionInfo":{"status":"ok","timestamp":1723214970233,"user_tz":-60,"elapsed":277,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class MDN(nn.Module):\n","    def __init__(self, input_dim, output_dim, num_mixtures):\n","        super(MDN, self).__init__()\n","        self.num_mixtures = num_mixtures\n","        self.output_dim = output_dim\n","\n","        self.fc1 = nn.Linear(input_dim, 64)\n","        self.fc2 = nn.Linear(64, 64)\n","        self.fc3 = nn.Linear(64, num_mixtures * (2 * output_dim + 1))\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        params = self.fc3(x)\n","\n","        means = params[:, :self.num_mixtures * self.output_dim]\n","        variances = params[:, self.num_mixtures * self.output_dim:2 * self.num_mixtures * self.output_dim]\n","        weights = params[:, 2 * self.num_mixtures * self.output_dim:]\n","\n","        means = means.view(-1, self.num_mixtures, self.output_dim)\n","        variances = torch.exp(variances.view(-1, self.num_mixtures, self.output_dim))\n","        weights = torch.softmax(weights, dim=1)\n","\n","        return means, variances, weights\n","\n","def mdn_loss(y_true, means, variances, weights):\n","    y_true = y_true.unsqueeze(1).expand_as(means)\n","    diff = y_true - means\n","    exponent = -0.5 * torch.sum((diff ** 2) / variances, dim=2)\n","    normalizer = -0.5 * y_true.size(2) * torch.log(2 * torch.pi * variances).sum(dim=2)\n","    log_probs = exponent + normalizer\n","    weighted_log_probs = log_probs + torch.log(weights)\n","    log_sum_exp = torch.logsumexp(weighted_log_probs, dim=1)\n","    return -log_sum_exp.mean()"],"metadata":{"id":"nfsDfzqkLqd9","executionInfo":{"status":"ok","timestamp":1723214891027,"user_tz":-60,"elapsed":4124,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["%pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ErzhKkvr3ndr","executionInfo":{"status":"ok","timestamp":1723214896298,"user_tz":-60,"elapsed":5277,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}},"outputId":"a37e33b9-6597-4d25-bc51-944f10f66c10"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"]}]},{"cell_type":"code","source":["import optuna\n","\n","\n","def create_model(trial):\n","    input_dim = 6\n","    output_dim = 2\n","    num_mixtures = trial.suggest_int('num_mixtures', 3, 10)\n","    num_units = trial.suggest_int('num_units', 32, 128)\n","    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n","\n","    model = MDN(input_dim, output_dim, num_mixtures)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    return model, optimizer\n","\n","def objective(trial):\n","    model, optimizer = create_model(trial)\n","    criterion = mdn_loss\n","    num_epochs = 50\n","\n","    # Training loop\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for batch_x, batch_y in train_loader:\n","            optimizer.zero_grad()\n","            means, variances, weights = model(batch_x)\n","            loss = criterion(batch_y, means, variances, weights)\n","            loss.backward()\n","            optimizer.step()\n","\n","    # Validation loss\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for batch_x, batch_y in val_loader:\n","            means, variances, weights = model(batch_x)\n","            loss = criterion(batch_y, means, variances, weights)\n","            val_loss += loss.item()\n","\n","    val_loss /= len(val_loader)\n","    return -val_loss  # Negate the loss to ensure Optuna maximizes the log-likelihood"],"metadata":{"id":"4RTwJP9hnWJB","executionInfo":{"status":"ok","timestamp":1723214949452,"user_tz":-60,"elapsed":317,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=50)\n","\n","\n","best_params = study.best_params\n","print('Best parameters: ', best_params)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":567},"id":"20sgpuO6L55F","outputId":"e7822b96-555d-472b-e345-eb9e949d15bb","executionInfo":{"status":"error","timestamp":1723214942907,"user_tz":-60,"elapsed":1804,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-08-09 14:49:01,430] A new study created in memory with name: no-name-3c298b0d-7e62-49cd-bfc0-31de1a18a657\n","<ipython-input-6-74e646f4418b>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n","[W 2024-08-09 14:49:02,888] Trial 0 failed with parameters: {'num_mixtures': 8, 'num_units': 53, 'learning_rate': 0.00036072786090956367} because of the following error: NameError(\"name 'train_loader' is not defined\").\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n","    value_or_values = func(trial)\n","  File \"<ipython-input-6-74e646f4418b>\", line 24, in objective\n","    for batch_x, batch_y in train_loader:\n","NameError: name 'train_loader' is not defined\n","[W 2024-08-09 14:49:02,890] Trial 0 failed with value None.\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'train_loader' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-74e646f4418b>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-74e646f4418b>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"]}]},{"cell_type":"code","source":["# Create the best model with optimal hyperparameters\n","\n","best_params = {'num_mixtures': 3, 'num_units': 37, 'learning_rate': 0.00013292213551810696}\n","\n","best_model, best_optimizer = create_model(optuna.trial.FixedTrial(best_params))\n","\n","# Training the best model\n","num_epochs = 50\n","criterion = mdn_loss\n","\n","for epoch in range(num_epochs):\n","    best_model.train()\n","    for batch_x, batch_y in train_loader:\n","        best_optimizer.zero_grad()\n","        means, variances, weights = best_model(batch_x)\n","        loss = criterion(batch_y, means, variances, weights)\n","        loss.backward()\n","        best_optimizer.step()\n","\n","# Evaluate the best model\n","best_model.eval()\n","test_loss = 0.0\n","with torch.no_grad():\n","    for batch_x, batch_y in val_loader:\n","        means, variances, weights = best_model(batch_x)\n","        loss = criterion(batch_y, means, variances, weights)\n","        test_loss += loss.item()\n","\n","test_loss /= len(val_loader)\n","print('Test loss: ', test_loss)\n"],"metadata":{"id":"ishNmqNnKUaW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723215061603,"user_tz":-60,"elapsed":85835,"user":{"displayName":"Basheq Tarifi","userId":"16877569244236318306"}},"outputId":"b80ecdfd-5125-40d7-ce11-0bbf1c131853"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-6fd9041719f9>:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n"]},{"output_type":"stream","name":"stdout","text":["Test loss:  -1.4457371273064261\n"]}]}]}